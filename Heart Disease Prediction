import pandas as pd
from tensorflow.keras import layers,models
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder,MinMaxScaler

df = pd.read_csv("D:/Files/heart.csv")
df1 = df.copy()
df1 = df1.drop(["FastingBS","RestingECG","MaxHR","ST_Slope"],axis = 1)
df1.head()

df1.isna().sum()
m = MinMaxScaler()
l = ["Age","RestingBP","Cholesterol","Oldpeak"]
for i in l:
    df1[i] = m.fit_transform(df1[[i]])
df1.head()

df2 = df1.copy()
# Initialize the OneHotEncoder
ohe = OneHotEncoder(drop='first', sparse_output=False)
# Columns to be encoded
ll = ["Sex", "ExerciseAngina", "ChestPainType"]
for i in ll:
    # Transform and create DataFrame for each column
    transformed_data = ohe.fit_transform(df2[[i]])
    transformed_df = pd.DataFrame(transformed_data, columns=ohe.get_feature_names_out([i]))
    # Concatenate with the original DataFrame
    df2 = pd.concat([df2.reset_index(drop=True), transformed_df.reset_index(drop=True)], axis=1)
df2 = df2.drop(['Sex','ChestPainType','ExerciseAngina'],axis = 1)
df2.head()

x = df2.drop("HeartDisease",axis = 1)
y = df2.HeartDisease
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 45)
print(x_train.shape,y_train.shape)

model = models.Sequential([
    layers.Flatten(input_shape=(9,)),
    layers.Dense(128,activation = 'relu'),
    layers.Dense(84,activation = 'relu'),
    layers.Dense(64,activation = 'relu'),
    layers.Dense(32,activation = 'relu'),
    layers.Dense(16,activation = 'relu'),
    layers.Dense(8,activation = 'relu'),
    layers.Dense(4,activation = 'relu'),
    layers.Dense(2,activation = 'relu'),
    layers.Dense(1,activation = 'softmax')
])

model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
model.fit(x_train,y_train,epochs = 50, validation_data=(x_test,y_test),validation_split=0.6)

#Calculating loss and accuracy
loss,accuracy = model.evaluate(x_test,y_test)
print(f"loss:{loss}\naccuracy:{accuracy}")

